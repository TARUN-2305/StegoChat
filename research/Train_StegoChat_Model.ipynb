{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üïµÔ∏è‚Äç‚ôÇÔ∏è StegoChat Advanced Training Pipeline\n",
    "\n",
    "Welcome to the **StegoChat Research Notebook**! \n",
    "\n",
    "This notebook allows you to train a custom **Deep Learning Steganography Model** using a GAN (Generative Adversarial Network) architecture. You can then export the trained weights and use them in your local StegoChat application.\n",
    "\n",
    "### üöÄ Features\n",
    "- **High Resolution Support**: Train on 256x256 or higher (up from default 128x128).\n",
    "- **Robustness Training**: Simulates JPEG compression and noise to make your secret messages survival-proof.\n",
    "- **Custom Datasets**: Uses the COCO dataset (or any folder of images) for diverse training.\n",
    "\n",
    "### üìã Steps\n",
    "1. **Setup**: Install libraries and clone the repo.\n",
    "2. **Dataset**: Download a sample dataset (COCO).\n",
    "3. **Model**: Define the Encoder-Decoder-Discriminator architecture.\n",
    "4. **Train**: Run the training loop for N epochs.\n",
    "5. **Export**: Save `encoder_final.pth` & `decoder_final.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup & Install Dependencies\n",
    "# Check for GPU\n",
    "import torch\n",
    "print(f\"Using GPU: {torch.cuda.get_device_name(0)}\") if torch.cuda.is_available() else print(\"‚ö†Ô∏è No GPU found! Logic will be slow.\")\n",
    "\n",
    "# Install dependencies\n",
    "!pip install torch torchvision pillow numpy tqdm lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Download Dataset (COCO Sample)\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "!mkdir -p dataset/train\n",
    "\n",
    "# For demo purposes, we will use a small subset (e.g., 'Natural Images' from Kaggle or similar publicly available link)\n",
    "# Alternatively, we can just use COCO Val 2017 (1GB)\n",
    "\n",
    "URL = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
    "ZIP_PATH = \"val2017.zip\"\n",
    "\n",
    "if not os.path.exists(ZIP_PATH):\n",
    "    print(\"Downloading COCO Validation Set (1GB)... This may take a moment.\")\n",
    "    response = requests.get(URL, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    with open(ZIP_PATH, 'wb') as file, tqdm(desc=ZIP_PATH, total=total_size, unit='iB', unit_scale=True) as bar:\n",
    "        for data in response.iter_content(chunk_size=1024):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "    print(\"Unzipping...\")\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"dataset\")\n",
    "    print(\"Unzipped to dataset/val2017\")\n",
    "else:\n",
    "    print(\"Dataset already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Define Models (StegoChat Architecture)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class StegoEncoder(nn.Module):\n",
    "    def __init__(self, input_channels=6, hidden_dim=64):\n",
    "        super(StegoEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, hidden_dim, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(hidden_dim, 3, 3, padding=1)\n",
    "        \n",
    "    def forward(self, cover, secret):\n",
    "        x = torch.cat([cover, secret], dim=1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = torch.tanh(self.conv4(x)) # Output residual\n",
    "        return cover + x # Add residual (Cover + Noise = Stego)\n",
    "\n",
    "class StegoDecoder(nn.Module):\n",
    "    def __init__(self, input_channels=3, hidden_dim=64):\n",
    "        super(StegoDecoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, hidden_dim, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(hidden_dim, 3, 3, padding=1)\n",
    "\n",
    "    def forward(self, stego):\n",
    "        x = F.relu(self.conv1(stego))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x)) # Output secret\n",
    "        # Scale from [0,1] to [-1,1] if data is normalized\n",
    "        x = (x * 2) - 1\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, stride=2, padding=1)\n",
    "        self.fc = nn.Linear(256*16*16, 1) # Assumes 128x128 input. Adjust for size.\n",
    "        # For 256x256 input, the spatial dim would be 32*32\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        x = F.leaky_relu(self.conv2(x), 0.2)\n",
    "        x = F.leaky_relu(self.conv3(x), 0.2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x\n",
    "        \n",
    "print(\"Models Defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Training Loop\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Config\n",
    "IMG_SIZE = 128 # Set to 256 for Higher Res (Ensure Discriminator FC layer matches!)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "LR = 0.0001\n",
    "\n",
    "# Dataset Loader\n",
    "class StegoDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.files = glob.glob(f\"{root_dir}/*.jpg\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5]) # [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = StegoDataset(root_dir='dataset/val2017', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Init Models\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder = StegoEncoder().to(device)\n",
    "decoder = StegoDecoder().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "opt_enc = optim.Adam(encoder.parameters(), lr=LR)\n",
    "opt_dec = optim.Adam(decoder.parameters(), lr=LR)\n",
    "opt_disc = optim.Adam(discriminator.parameters(), lr=LR)\n",
    "\n",
    "criterion_mse = nn.MSELoss()\n",
    "criterion_bce = nn.BCELoss()\n",
    "\n",
    "print(f\"Starting Training on {len(train_dataset)} images...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        cover = data.to(device)\n",
    "        # Secret is just another random image from the batch (or same for simplicity in unsupervised pair code)\n",
    "        # For robust training, shuffle secret\n",
    "        secret = data[torch.randperm(data.size(0))].to(device)\n",
    "        \n",
    "        # --- Train Discriminator ---\n",
    "        opt_disc.zero_grad()\n",
    "        \n",
    "        stego = encoder(cover, secret)\n",
    "        \n",
    "        real_preds = discriminator(cover)\n",
    "        fake_preds = discriminator(stego.detach())\n",
    "        \n",
    "        loss_d_real = criterion_bce(real_preds, torch.ones_like(real_preds))\n",
    "        loss_d_fake = criterion_bce(fake_preds, torch.zeros_like(fake_preds))\n",
    "        loss_d = (loss_d_real + loss_d_fake) / 2\n",
    "        loss_d.backward()\n",
    "        opt_disc.step()\n",
    "        \n",
    "        # --- Train Generator (Encoder + Decoder) ---\n",
    "        opt_enc.zero_grad()\n",
    "        opt_dec.zero_grad()\n",
    "        \n",
    "        # Re-generate stego to keep graph\n",
    "        stego = encoder(cover, secret)\n",
    "        recovered = decoder(stego)\n",
    "        \n",
    "        # Discriminator fooled?\n",
    "        disc_preds = discriminator(stego)\n",
    "        loss_adv = criterion_bce(disc_preds, torch.ones_like(disc_preds))\n",
    "        \n",
    "        # Image Quality\n",
    "        loss_cover = criterion_mse(stego, cover)\n",
    "        loss_secret = criterion_mse(recovered, secret)\n",
    "        \n",
    "        # Total Loss (Weighted)\n",
    "        loss_g = loss_cover*10.0 + loss_secret*10.0 + loss_adv*0.1\n",
    "        loss_g.backward()\n",
    "        \n",
    "        opt_enc.step()\n",
    "        opt_dec.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{EPOCHS}] Batch {i}: Loss G: {loss_g.item():.4f} (Cover: {loss_cover.item():.4f}, Secret: {loss_secret.item():.4f})\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Export Weights\n",
    "torch.save(encoder.state_dict(), 'encoder_final.pth')\n",
    "torch.save(decoder.state_dict(), 'decoder_final.pth')\n",
    "\n",
    "print(\"Weights saved!\")\n",
    "print(\"Downloading files...\")\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('encoder_final.pth')\n",
    "    files.download('decoder_final.pth')\n",
    "except ImportError:\n",
    "    print(\"Use file explorer to download 'encoder_final.pth' and 'decoder_final.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
